{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pelle\\AppData\\Local\\Temp\\ipykernel_14172\\4164245003.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Patient_ID  Age  Blood_Pressure  CVD_Risk_Score  Gender_Male  \\\n",
      "0           1   55             104              78            1   \n",
      "1           2   66             142              49            0   \n",
      "2           3   69             176              31            0   \n",
      "3           4   45             178              23            0   \n",
      "4           5   39             146              79            0   \n",
      "\n",
      "   Smoking_Status_Smoker  Cholesterol_Level_Low  Cholesterol_Level_Normal  \\\n",
      "0                      0                      0                         1   \n",
      "1                      1                      1                         0   \n",
      "2                      1                      1                         0   \n",
      "3                      1                      0                         1   \n",
      "4                      1                      0                         1   \n",
      "\n",
      "   Air_Pollution_Exposure_Low  Air_Pollution_Exposure_Medium  ...  \\\n",
      "0                           0                              0  ...   \n",
      "1                           0                              1  ...   \n",
      "2                           0                              1  ...   \n",
      "3                           0                              1  ...   \n",
      "4                           0                              1  ...   \n",
      "\n",
      "   Income_Level_Middle  Hypertension_Yes  Diabetes_Yes  Obesity_Yes  \\\n",
      "0                    0                 0             0            1   \n",
      "1                    1                 1             0            0   \n",
      "2                    0                 0             0            0   \n",
      "3                    0                 0             1            0   \n",
      "4                    1                 0             0            0   \n",
      "\n",
      "   Alcohol_Consumption_Yes  Family_History_CVD_Yes  TCM_Use_Yes  \\\n",
      "0                        1                       0            1   \n",
      "1                        0                       1            0   \n",
      "2                        0                       0            0   \n",
      "3                        1                       0            1   \n",
      "4                        0                       0            0   \n",
      "\n",
      "   Chronic_Kidney_Disease_Yes  Previous_Heart_Attack_Yes  Heart_Attack_Yes  \n",
      "0                           1                          0                 0  \n",
      "1                           0                          0                 0  \n",
      "2                           0                          0                 0  \n",
      "3                           0                          1                 0  \n",
      "4                           1                          0                 0  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "import pickle\n",
    "with open('../Data/cleanedDF.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparaing the data\n",
    "X = df.drop('Heart_Attack_Yes', axis=1)\n",
    "y = df['Heart_Attack_Yes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forrest:  0.8784636603000794\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94     42038\n",
      "           1       0.00      0.00      0.00      5816\n",
      "\n",
      "    accuracy                           0.88     47854\n",
      "   macro avg       0.44      0.50      0.47     47854\n",
      "weighted avg       0.77      0.88      0.82     47854\n",
      "\n",
      "Accuracy of Decision Tree:  0.7649517281731935\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86     42038\n",
      "           1       0.12      0.15      0.13      5816\n",
      "\n",
      "    accuracy                           0.76     47854\n",
      "   macro avg       0.50      0.50      0.50     47854\n",
      "weighted avg       0.79      0.76      0.78     47854\n",
      "\n",
      "Accuracy of Naive Bayes:  0.8784636603000794\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94     42038\n",
      "           1       0.00      0.00      0.00      5816\n",
      "\n",
      "    accuracy                           0.88     47854\n",
      "   macro avg       0.44      0.50      0.47     47854\n",
      "weighted avg       0.77      0.88      0.82     47854\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forrest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Decision Tree\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluating models\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "print(\"Accuracy of Random Forrest: \", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))\n",
    "\n",
    "dt_predictions = dt_classifier.predict(X_test)\n",
    "print(\"Accuracy of Decision Tree: \", accuracy_score(y_test, dt_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_predictions))\n",
    "\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "print(\"Accuracy of Naive Bayes: \", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, nb_predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances (Random Forest):\n",
      "                            Feature  Importance\n",
      "0                        Patient_ID    0.113505\n",
      "3                    CVD_Risk_Score    0.099701\n",
      "2                    Blood_Pressure    0.099033\n",
      "1                               Age    0.094600\n",
      "4                       Gender_Male    0.018678\n",
      "44                      TCM_Use_Yes    0.018124\n",
      "5             Smoking_Status_Smoker    0.017628\n",
      "18             Rural_or_Urban_Urban    0.017224\n",
      "42          Alcohol_Consumption_Yes    0.016323\n",
      "30        Hospital_Availability_Low    0.016140\n",
      "31     Hospital_Availability_Medium    0.016013\n",
      "9     Air_Pollution_Exposure_Medium    0.015975\n",
      "43           Family_History_CVD_Yes    0.015758\n",
      "12              Diet_Score_Moderate    0.015721\n",
      "39                 Hypertension_Yes    0.015692\n",
      "14                 Stress_Level_Low    0.015441\n",
      "10            Physical_Activity_Low    0.015389\n",
      "7          Cholesterol_Level_Normal    0.015301\n",
      "13                  Diet_Score_Poor    0.015187\n",
      "15              Stress_Level_Medium    0.015115\n",
      "16       Healthcare_Access_Moderate    0.014919\n",
      "17           Healthcare_Access_Poor    0.014771\n",
      "11         Physical_Activity_Medium    0.014752\n",
      "37                 Income_Level_Low    0.014697\n",
      "38              Income_Level_Middle    0.014392\n",
      "6             Cholesterol_Level_Low    0.014245\n",
      "41                      Obesity_Yes    0.014180\n",
      "8        Air_Pollution_Exposure_Low    0.013782\n",
      "36  Education_Level_Unknown or None    0.013694\n",
      "34          Education_Level_Primary    0.013370\n",
      "32        Employment_Status_Retired    0.013144\n",
      "33     Employment_Status_Unemployed    0.013058\n",
      "35        Education_Level_Secondary    0.013002\n",
      "21                  Region_Southern    0.012410\n",
      "45       Chronic_Kidney_Disease_Yes    0.012332\n",
      "19                   Region_Eastern    0.011855\n",
      "22                   Region_Western    0.011716\n",
      "20                  Region_Northern    0.011629\n",
      "40                     Diabetes_Yes    0.010692\n",
      "29                 Province_Sichuan    0.010542\n",
      "27                Province_Shandong    0.010415\n",
      "46        Previous_Heart_Attack_Yes    0.010264\n",
      "24               Province_Guangdong    0.010201\n",
      "25                   Province_Henan    0.010129\n",
      "26                 Province_Qinghai    0.009995\n",
      "28                Province_Shanghai    0.009730\n",
      "23                   Province_Gansu    0.009540\n"
     ]
    }
   ],
   "source": [
    "# Now lets check which of the features are the most important for the Random Forrest Classifier\n",
    "rf_feature_importances = rf_classifier.feature_importances_\n",
    "features = X.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': rf_feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances (Random Forest):\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters for Random Forest:\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 288}\n",
      "Best score:  0.8785081395105845\n",
      "Best estimator:  RandomForestClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=9,\n",
      "                       n_estimators=288, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 301),\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # how many combos to try\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "best_rf_classifier = random_search.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters for Random Forest:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n",
    "print(\"Best estimator: \", best_rf_classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forrest with hyperparameters:  0.8784636603000794\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94     42038\n",
      "           1       0.00      0.00      0.00      5816\n",
      "\n",
      "    accuracy                           0.88     47854\n",
      "   macro avg       0.44      0.50      0.47     47854\n",
      "weighted avg       0.77      0.88      0.82     47854\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIjCAYAAAAk+FJEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzVUlEQVR4nO3de3zO9f/H8ee1YcbMZs5hTplhjvWV8/kYYQmpbA5F6ZucI8eJRSanHIoYOeawknKItAgp50NiTsmc5mwz7Lp+f/i5vl2NbGyut+1xv93cbnlfn+vzeX12kx599rk+s9hsNpsAAAAAA7k4ewAAAADgfohVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQC4h0OHDqlhw4bKnj27LBaLIiIiUnT/x44dk8Vi0ezZs1N0v0+y2rVrq3bt2s4eA4BhiFUAxoqKilLXrl1VtGhRZc6cWZ6enqpWrZomTJiguLi4VD12UFCQ9uzZo5EjR2ru3Ll65plnUvV4j1NwcLAsFos8PT3v+XU8dOiQLBaLLBaLxo4dm+z9nzp1SsOGDdPOnTtTYFoA6V0GZw8AAPeycuVKvfTSS3Jzc1OHDh1UpkwZ3bx5Uxs3blTfvn21b98+ffrpp6ly7Li4OG3evFnvv/++3n777VQ5hq+vr+Li4pQxY8ZU2f+DZMiQQbGxsVqxYoXatGnj8Nq8efOUOXNm3bhx46H2ferUKQ0fPlyFCxdW+fLlk/y+NWvWPNTxAKRtxCoA4xw9elTt2rWTr6+v1q9fr3z58tlf6969uw4fPqyVK1em2vHPnTsnSfLy8kq1Y1gsFmXOnDnV9v8gbm5uqlatmhYsWJAoVufPn6/nn39eS5cufSyzxMbGKkuWLMqUKdNjOR6AJwu3AQAwzpgxY3Tt2jXNnDnTIVTvKl68uHr06GH//e3btzVixAgVK1ZMbm5uKly4sAYOHKj4+HiH9xUuXFjNmjXTxo0b9Z///EeZM2dW0aJFNWfOHPs2w4YNk6+vrySpb9++slgsKly4sKQ73z6/+89/N2zYMFksFoe1tWvXqnr16vLy8pKHh4f8/Pw0cOBA++v3u2d1/fr1qlGjhrJmzSovLy+1aNFCBw4cuOfxDh8+rODgYHl5eSl79uzq2LGjYmNj7/+F/Yf27dvru+++06VLl+xr27Zt06FDh9S+fftE21+4cEF9+vRRQECAPDw85OnpqSZNmmjXrl32bTZs2KBnn31WktSxY0f77QR3z7N27doqU6aMfvvtN9WsWVNZsmSxf13+ec9qUFCQMmfOnOj8GzVqJG9vb506dSrJ5wrgyUWsAjDOihUrVLRoUVWtWjVJ23fp0kVDhgxRxYoV9fHHH6tWrVoKDQ1Vu3btEm17+PBhtW7dWg0aNFBYWJi8vb0VHBysffv2SZICAwP18ccfS5JefvllzZ07V+PHj0/W/Pv27VOzZs0UHx+vkJAQhYWF6YUXXtCmTZv+9X3ff/+9GjVqpLNnz2rYsGHq1auXfv75Z1WrVk3Hjh1LtH2bNm109epVhYaGqk2bNpo9e7aGDx+e5DkDAwNlsVi0bNky+9r8+fNVsmRJVaxYMdH2R44cUUREhJo1a6Zx48apb9++2rNnj2rVqmUPR39/f4WEhEiS3njjDc2dO1dz585VzZo17fuJiYlRkyZNVL58eY0fP1516tS553wTJkxQrly5FBQUpISEBEnS9OnTtWbNGk2aNEn58+dP8rkCeILZAMAgly9ftkmytWjRIknb79y50ybJ1qVLF4f1Pn362CTZ1q9fb1/z9fW1SbJFRkba186ePWtzc3Oz9e7d27529OhRmyTbRx995LDPoKAgm6+vb6IZhg4davv7X6cff/yxTZLt3Llz95377jFmzZplXytfvrwtd+7ctpiYGPvarl27bC4uLrYOHTokOl6nTp0c9tmqVSubj4/PfY/59/PImjWrzWaz2Vq3bm2rV6+ezWaz2RISEmx58+a1DR8+/J5fgxs3btgSEhISnYebm5stJCTEvrZt27ZE53ZXrVq1bJJs06ZNu+drtWrVclhbvXq1TZLtgw8+sB05csTm4eFha9my5QPPEUDawZVVAEa5cuWKJClbtmxJ2v7bb7+VJPXq1cthvXfv3pKU6N7WUqVKqUaNGvbf58qVS35+fjpy5MhDz/xPd+91/eqrr2S1WpP0nujoaO3cuVPBwcHKkSOHfb1s2bJq0KCB/Tz/rlu3bg6/r1GjhmJiYuxfw6Ro3769NmzYoNOnT2v9+vU6ffr0PW8BkO7c5+ricuc/GwkJCYqJibHf4rB9+/YkH9PNzU0dO3ZM0rYNGzZU165dFRISosDAQGXOnFnTp09P8rEAPPmIVQBG8fT0lCRdvXo1SdsfP35cLi4uKl68uMN63rx55eXlpePHjzusFypUKNE+vL29dfHixYecOLG2bduqWrVq6tKli/LkyaN27dpp8eLF/xqud+f08/NL9Jq/v7/Onz+v69evO6z/81y8vb0lKVnn0rRpU2XLlk2LFi3SvHnz9Oyzzyb6Wt5ltVr18ccf6+mnn5abm5ty5sypXLlyaffu3bp8+XKSj/nUU08l68NUY8eOVY4cObRz505NnDhRuXPnTvJ7ATz5iFUARvH09FT+/Pm1d+/eZL3vnx9wuh9XV9d7rttstoc+xt37Ke9yd3dXZGSkvv/+e7322mvavXu32rZtqwYNGiTa9lE8yrnc5ebmpsDAQIWHh2v58uX3vaoqSaNGjVKvXr1Us2ZNffHFF1q9erXWrl2r0qVLJ/kKsnTn65McO3bs0NmzZyVJe/bsSdZ7ATz5iFUAxmnWrJmioqK0efPmB27r6+srq9WqQ4cOOayfOXNGly5dsn+yPyV4e3s7fHL+rn9evZUkFxcX1atXT+PGjdP+/fs1cuRIrV+/Xj/88MM99313zoMHDyZ67ffff1fOnDmVNWvWRzuB+2jfvr127Nihq1ev3vNDaXctWbJEderU0cyZM9WuXTs1bNhQ9evXT/Q1Ser/OCTF9evX1bFjR5UqVUpvvPGGxowZo23btqXY/gGYj1gFYJx+/fopa9as6tKli86cOZPo9aioKE2YMEHSnW9jS0r0if1x48ZJkp5//vkUm6tYsWK6fPmydu/ebV+Ljo7W8uXLHba7cOFCovfefTj+Px+ndVe+fPlUvnx5hYeHO8Tf3r17tWbNGvt5poY6depoxIgRmjx5svLmzXvf7VxdXRNdtf3yyy/1119/Oazdjep7hX1y9e/fXydOnFB4eLjGjRunwoULKygo6L5fRwBpDz8UAIBxihUrpvnz56tt27by9/d3+AlWP//8s7788ksFBwdLksqVK6egoCB9+umnunTpkmrVqqVffvlF4eHhatmy5X0fi/Qw2rVrp/79+6tVq1Z65513FBsbq6lTp6pEiRIOHzAKCQlRZGSknn/+efn6+urs2bOaMmWKChQooOrVq993/x999JGaNGmiKlWqqHPnzoqLi9OkSZOUPXt2DRs2LMXO459cXFw0aNCgB27XrFkzhYSEqGPHjqpatar27NmjefPmqWjRog7bFStWTF5eXpo2bZqyZcumrFmzqnLlyipSpEiy5lq/fr2mTJmioUOH2h+lNWvWLNWuXVuDBw/WmDFjkrU/AE8mrqwCMNILL7yg3bt3q3Xr1vrqq6/UvXt3vffeezp27JjCwsI0ceJE+7YzZszQ8OHDtW3bNr377rtav369BgwYoIULF6boTD4+Plq+fLmyZMmifv36KTw8XKGhoWrevHmi2QsVKqTPP/9c3bt31yeffKKaNWtq/fr1yp49+333X79+fa1atUo+Pj4aMmSIxo4dq+eee06bNm1KduilhoEDB6p3795avXq1evTooe3bt2vlypUqWLCgw3YZM2ZUeHi4XF1d1a1bN7388sv68ccfk3Wsq1evqlOnTqpQoYLef/99+3qNGjXUo0cPhYWFacuWLSlyXgDMZrEl5058AAAA4DHiyioAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMlSZ/gpV7hbedPQIApKiL2yY7ewQASFGZk1ihXFkFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYy7hYtdlsstlszh4DAAAABjAmVufMmaOAgAC5u7vL3d1dZcuW1dy5c509FtKwPh0bKG7HZH3U50VJkrdnFo3r/5J2LR+sC5vH6Y9vQxTWr7U8PTI7vK9gXm8tm9hNMT+P0/F1oRr1bku5uv7vX6Wq5Ytq/ayeOvnDaF3YPE47lw3Sf1+p47APFxeLhrz1vA58M0wXNo/Tvq+H6r3XG6f+SQPAv1g4f56aNKirZysE6JV2L2nP7t3OHglQBmcPIEnjxo3T4MGD9fbbb6tatWqSpI0bN6pbt246f/68evbs6eQJkdZUKlVInV+spt1/nLSv5cuVXflyZdeAj5frwJHTKpQvhya93075cmVX+74zJd2JzGUT39SZmCuqExymvLmya8aI13TrdoKGTl4hSboed1PTFkVqzx9/6XrcTVWtUEyTB7XT9bib+nzZJklS7+AGer11Db0+ZK72R0WrUulCmj7sVV25FqcpC358/F8QAOnequ++1dgxoRo0dLgCAspp3txwvdm1s776ZpV8fHycPR7SMYvNgO+5FylSRMOHD1eHDh0c1sPDwzVs2DAdPXo0Wftzr/B2So6HNCareyZtXvCeeoQu0ntdGmv3wZPqO3bpPbcNrF9Bn4/sIJ+qvZWQYFXDaqW0bEI3FW34vs5euCpJ6tK6uj54p4UK1n1Pt24n3HM/C8d20fW4m+o8eI4kaemEbjp74YreHD7fvs2CsV0Ud+OmOg2ak8JnjLTg4rbJzh4Badwr7V5S6TIBGjhoiCTJarWqYb1aern9a+r8+htOng5pUeYkXjI14jaA6OhoVa1aNdF61apVFR0d7YSJkJaNH9BWq37aqx+2Hnzgtp7ZMuvK9RtKSLBKkiqXLaK9h0/ZQ1WS1v58QNmzuatUsXz33Ec5vwKqXK6oftp+yL62ZdcR1fmPn4oXyi1JCijxlKqUL6o1m/Y/yqkBwEO5dfOmDuzfp+eq/O+/xS4uLnruuaravWuHEycDDLkNoHjx4lq8eLEGDhzosL5o0SI9/fTT//re+Ph4xcfHO6zZrAmyuLim+Jx48r3UqJLKlyyo6q+OeeC2Pl5ZNeD1Jvp86c/2tTw+njobc9Vhu7MXrtx5Laen9Lf+PbxqhHJ6eyiDq6s+mP6tZi/fbH9t7Ky18vTIrF3LBykhwSZXV4uGfvKNFn736yOeIQAk38VLF5WQkJDo2/0+Pj46evSIk6YC7jAiVocPH662bdsqMjLSfs/qpk2btG7dOi1evPhf3xsaGqrhw4c7rLnmeVYZ8/0n1ebFk6lAHi991PdFNXtzsuJv3v7XbbNlzazlE9/UgSPR+mD6yoc6Xr1O4+WRxU3/CSisEe+00JE/z2nxqt8kSa0bVlS7Js8qeGC49kdFq6zfU/qoT2tFn7useSu2PtTxAABIi4yI1RdffFFbt27VuHHjFBERIUny9/fXL7/8ogoVKvzrewcMGKBevXo5rOWu0T+1RsUTrIJ/IeXx8dTm+f/785Ehg6uqVyymbm1rKnvld2W12uSRxU1ff/KWrsbeUNten+n2bat9+zMxV/RMGV+H/ebO4XnntfNXHNaPn4qRJO07fEq5fbLp/a5N7bE66t2WGjtrrb5c/Zt9m0L5cqhvxwbEKoDHztvLW66uroqJiXFYj4mJUc6cOZ00FXCHEbEqSZUqVdK8efOS/T43Nze5ubk5rHELAO7lh18OqlLrkQ5rnw5/VQePnlHY7LWyWm3KljWzVkzprvibt9X63emJrsBu3X1U/Ts3Ui5vD527eE2SVO+5krp8NU4Hjpy+77FdXCxyy/S/f93cM2eS1WZ12CbBapOLixG3kQNIZzJmyiT/UqW1dctm1a1XX9KdD1ht3bpZ7V5+1cnTIb1zaqy6uLjIYrH86zYWi0W3b//7t2yBpLgWG6/9UY4f2Lsed1MXLl/X/qhoZcuaWd9M6S73zJnU8f1weWbNLM+sd56xeu7iNVmtNn2/+YAOHDmtmR8E6f0JEcrj46mh3Ztp+uJI3bx1589p1zY19efpCzp47IwkqXrF4nr3tXoOj6T6NnKP+ndupD+jL2p/VLTKlyygd16tozkRWx7TVwMAHL0W1FGDB/ZX6dJlVCagrL6YG664uDi1bBXo7NGQzjk1VpcvX37f1zZv3qyJEyfKarXedxsgJZUvWVD/KVtEkrR/xTCH1/yaDtGJ6AuyWm16scdUTRjYThtm99b1G/Gat+IXhUz9332tLi4Whfz3BRV+yke3b1t15OR5DZr4lWYs2WTfptfoLzX0rWaaMLCtcnl7KPrcZc1cskmjPv3usZwrAPxT4yZNdfHCBU2ZPFHnz5+TX0l/TZk+Qz7cBgAnM+I5q3938OBBvffee1qxYoVeeeUVhYSEyNfX98Fv/BueswogreE5qwDSmifqOauSdOrUKb3++usKCAjQ7du3tXPnToWHhyc7VAEAAJB2OD1WL1++rP79+6t48eLat2+f1q1bpxUrVqhMmTLOHg0AAABO5tR7VseMGaPRo0crb968WrBggVq0aOHMcQAAAGAYp96z6uLiInd3d9WvX1+urvd/3NSyZcuStV/uWQWQ1nDPKoC0Jqn3rDr1ymqHDh0e+OgqAAAApF9OjdXZs2c78/AAAAAwnNM/YAUAAADcD7EKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwVoakbPT1118neYcvvPDCQw8DAAAA/F2SYrVly5ZJ2pnFYlFCQsKjzAMAAADYJSlWrVZras8BAAAAJMI9qwAAADBWkq6s/tP169f1448/6sSJE7p586bDa++8806KDAYAAAAkO1Z37Nihpk2bKjY2VtevX1eOHDl0/vx5ZcmSRblz5yZWAQAAkGKSfRtAz5491bx5c128eFHu7u7asmWLjh8/rkqVKmns2LGpMSMAAADSqWTH6s6dO9W7d2+5uLjI1dVV8fHxKliwoMaMGaOBAwemxowAAABIp5IdqxkzZpSLy5235c6dWydOnJAkZc+eXX/++WfKTgcAAIB0Ldn3rFaoUEHbtm3T008/rVq1amnIkCE6f/685s6dqzJlyqTGjAAAAEinkn1lddSoUcqXL58kaeTIkfL29tabb76pc+fO6dNPP03xAQEAAJB+WWw2m83ZQ6Q09wpvO3sEAEhRF7dNdvYIAJCiMifx+/v8UAAAAAAYK9n3rBYpUkQWi+W+rx85cuSRBgIAAADuSnasvvvuuw6/v3Xrlnbs2KFVq1apb9++KTUXAAAAkPxY7dGjxz3XP/nkE/3666+PPBAAAABwV4rds9qkSRMtXbo0pXYHAAAApFysLlmyRDly5Eip3QEAAAAP90MB/v4BK5vNptOnT+vcuXOaMmVKig4HAACA9C3ZsdqiRQuHWHVxcVGuXLlUu3ZtlSxZMkWHe1h7V3/k7BEAAACQAtLkDwWIOhvn7BEAIEU9lcPd2SMAQIpKtR8K4OrqqrNnzyZaj4mJkaura3J3BwAAANxXsmP1fhdi4+PjlSlTpkceCAAAALgryfesTpw4UZJksVg0Y8YMeXh42F9LSEhQZGSkMfesAgAAIG1I8j2rRYoUkSQdP35cBQoUcPiWf6ZMmVS4cGGFhISocuXKqTNpMnDPKoC0hntWAaQ1Sb1nNclXVo8ePSpJqlOnjpYtWyZvb++HGgwAAABIKp4GAABPAK6sAkhrUu1pAC+++KJGjx6daH3MmDF66aWXkrs7AAAA4L6SHauRkZFq2rRpovUmTZooMjIyRYYCAAAApIeI1WvXrt3zEVUZM2bUlStXUmQoAAAAQHqIWA0ICNCiRYsSrS9cuFClSpVKkaEAAAAAKRlPA7hr8ODBCgwMVFRUlOrWrStJWrdunebPn68lS5ak+IAAAABIv5Idq82bN1dERIRGjRqlJUuWyN3dXeXKldP69euVI0eO1JgRAAAA6dQjP7rqypUrWrBggWbOnKnffvtNCQkJKTXbQ+PRVQDSGh5dBSCtSbVHV90VGRmpoKAg5c+fX2FhYapbt662bNnysLsDAAAAEknWbQCnT5/W7NmzNXPmTF25ckVt2rRRfHy8IiIi+HAVAAAAUlySr6w2b95cfn5+2r17t8aPH69Tp05p0qRJqTkbAAAA0rkkX1n97rvv9M477+jNN9/U008/nZozAQAAAJKScWV148aNunr1qipVqqTKlStr8uTJOn/+fGrOBgAAgHQuybH63HPP6bPPPlN0dLS6du2qhQsXKn/+/LJarVq7dq2uXr2amnMCAAAgHXqkR1cdPHhQM2fO1Ny5c3Xp0iU1aNBAX3/9dUrO91B4dBWAtIZHVwFIa1L90VWS5OfnpzFjxujkyZNasGDBo+wKAAAASOSRfyiAibiyCiCt4coqgLTmsVxZBQAAAFITsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYzk1VuPi4hQbG2v//fHjxzV+/HitWbPGiVMBAADAFE6N1RYtWmjOnDmSpEuXLqly5coKCwtTixYtNHXqVGeOBgAAAAM4NVa3b9+uGjVqSJKWLFmiPHny6Pjx45ozZ44mTpzozNEAAABgAKfGamxsrLJlyyZJWrNmjQIDA+Xi4qLnnntOx48fd+ZoAAAAMEAGZx68ePHiioiIUKtWrbR69Wr17NlTknT27Fl5eno6czSkE198PlXzZ013WCtQqLA+nRchSboQc14zp3ysnb9uUWzsdRUoWFhtO3RR9dr17dsvnPOZtm3+SUcO/aEMGTPoy+823vNYa7/9SssXfaG/Th5XlixZVb1OA3XvNTDVzg0Akmvh/HkKnzVT58+fUwm/knpv4GAFlC3r7LGQzjk1VocMGaL27durZ8+eqlu3rqpUqSLpzlXWChUqOHM0pCO+RYpp5Mf/C1ZXV1f7P4eNHKTr165qSOh4eXp5a8Pa7/Th0H6a8Nl8FStRUpJ0+9YtVa/dQCVLl9OalcvveYxlC+dq+aI56vRWT5UsFaAbcXE6c/pU6p4YACTDqu++1dgxoRo0dLgCAspp3txwvdm1s776ZpV8fHycPR7SMafGauvWrVW9enVFR0erXLly9vV69eqpVatWTpwM6Ymrq6ty+OS852sH9u5S917vy69UgCTp5aDXFbH4Cx06uN8eq692fkvSnSun93L16hXNnfGJhn44QeWfqWxfL1K8REqeBgA8krnhsxTYuo1atnpRkjRo6HBFRm5QxLKl6vz6G06eDumZ05+zmjdvXmXLlk1r165VXFycJOnZZ59VyZIlnTwZ0ou/Tp7Qqy0bqFOb5zUmZIDOnom2v+Zfppwi16/W1SuXZbVa9eP3q3TzZrzKVngmyfvfsW2zrDarYs6fVddXW+m1wIYaNaSvzp05nRqnAwDJduvmTR3Yv0/PValqX7vzGZKq2r1rhxMnA5wcqzExMapXr55KlCihpk2bKjr6TiR07txZvXv3TtI+4uPjdeXKFYdf8fHxqTk20hC/UgHqNTBEI8Z+ou6939eZ6L/Ut3snxcZelyQNGD5GCbdvq+3ztdSi7n80aewHGjxynPIXKJTkY5w+9ZdsVqsWzZ2pN/7bV++PGKtrV67o/V7ddOvWrdQ6NQBIsouXLiohISHRt/t9fHx0/vx5J00F3OHUWO3Zs6cyZsyoEydOKEuWLPb1tm3batWqVUnaR2hoqLJnz+7wa9rEj1JrZKQxzz5XXTXqNFSR4iVUqXJVDR8zWdevXdVP6+/8YIq5M6bo2rWrGvXxdE2YMU+t2r6q0KH9dDTqUJKPYbNadfv2bXXr0U+VKldVydJl1X9oqE6dPKHd27el1qkBAJAmOPWe1TVr1mj16tUqUKCAw/rTTz+d5EdXDRgwQL169XJYO3nZmmIzIn3xyOappwoW0qmTfyr6rz+1YtlCTZ2zRL5FikuSihb3075dO/TN8kX6b59BSdqn9//fD1uocDH7WnbvHPLM7qVzf7vlAACcxdvLW66uroqJiXFYj4mJUc6c976nH3hcnHpl9fr16w5XVO+6cOGC3NzckrQPNzc3eXp6OvxK6nuBf4qLjVX0XyeVI2dO3bhxQ5JksTj+a+Li4iKbNen/Q1Qq4M6TLU6eOGZfu3rlsq5cvqTcefM9+tAA8IgyZsok/1KltXXLZvua1WrV1q2bVbYcT+eBczklVk+duvPInho1ath/3KokWSwWWa1WjRkzRnXq1HHGaEhnZnwyTnt2/Koz0X9p/56dGvF+T7m4uKp2vcYq6FtY+QsU1KSxH+jg/j2K/utPLVs4Rzt+3aIqNf735/PsmWhFHfpd586cljXBqqhDvyvq0O+Ki42VJBUo5KvnqtfW9IljtH/PTh07clhhIwerQKHCKlvxWWedOgA4eC2oo5YtWayvI5brSFSUPggZpri4OLVsFejs0ZDOWWw2m+1xH9Tb21uffPKJypUrp7p166pixYpav369XnjhBe3bt08XLlzQpk2bVKxYsQfv7B6izsal8MRIqz4c2l97d23XlSuXlN3LW6UDKijojbeV76mCkqS//jyuWdMnav/uHYqLi1X+pwopsF0H1WvczL6PcSMH6/tVKxLve+JnKlvhTozGXr+mTyeN1c8/rpPFxUUB5Sup6zv9lCtP3sdzonjiPZXD3dkjIB1YMO8L+w8F8Cvpr/4DB6ls2XIPfiPwEDIn8WZUp8TqlClT1L9/fzVu3FjTpk3TtGnTtGvXLl27dk0VK1ZU9+7dlS/fw397lFgFkNYQqwDSGqNjVZKOHj2qzp07a//+/fr000/1wgsvpNi+iVUAaQ2xCiCtMT5W75o8ebJ69uwpf39/ZcjgOPX27dsfap/EKoC0hlgFkNYkNVad+uiq48ePa9myZfL29laLFi0SxSoAAADSN6fV4WeffabevXurfv362rdvn3LlyuWsUQAAAGAop8Rq48aN9csvv2jy5Mnq0KGDM0YAAADAE8ApsZqQkKDdu3cn+slVAAAAwN85/QNWqYEPWAFIa/iAFYC0JqkfsHLqj1sFAAAA/g2xCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMJbFZrPZnD0E8CSKj49XaGioBgwYIDc3N2ePAwCPjL/XYCJiFXhIV65cUfbs2XX58mV5eno6exwAeGT8vQYTcRsAAAAAjEWsAgAAwFjEKgAAAIxFrAIPyc3NTUOHDuVDCADSDP5eg4n4gBUAAACMxZVVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFXgXwQHB8tisejDDz90WI+IiJDFYnHSVACQPDabTfXr11ejRo0SvTZlyhR5eXnp5MmTTpgMeDBiFXiAzJkza/To0bp48aKzRwGAh2KxWDRr1ixt3bpV06dPt68fPXpU/fr106RJk1SgQAEnTgjcH7EKPED9+vWVN29ehYaG3nebpUuXqnTp0nJzc1PhwoUVFhb2GCcEgAcrWLCgJkyYoD59+ujo0aOy2Wzq3LmzGjZsqAoVKqhJkyby8PBQnjx59Nprr+n8+fP29y5ZskQBAQFyd3eXj4+P6tevr+vXrzvxbJCeEKvAA7i6umrUqFGaNGnSPb9N9ttvv6lNmzZq166d9uzZo2HDhmnw4MGaPXv24x8WAP5FUFCQ6tWrp06dOmny5Mnau3evpk+frrp166pChQr69ddftWrVKp05c0Zt2rSRJEVHR+vll19Wp06ddODAAW3YsEGBgYHiMe14XPihAMC/CA4O1qVLlxQREaEqVaqoVKlSmjlzpiIiItSqVSvZbDa98sorOnfunNasWWN/X79+/bRy5Urt27fPidMDQGJnz55V6dKldeHCBS1dulR79+7VTz/9pNWrV9u3OXnypAoWLKiDBw/q2rVrqlSpko4dOyZfX18nTo70iiurQBKNHj1a4eHhOnDggMP6gQMHVK1aNYe1atWq6dChQ0pISHicIwLAA+XOnVtdu3aVv7+/WrZsqV27dumHH36Qh4eH/VfJkiUlSVFRUSpXrpzq1aungIAAvfTSS/rss8+4hx+PFbEKJFHNmjXVqFEjDRgwwNmjAMAjyZAhgzJkyCBJunbtmpo3b66dO3c6/Dp06JBq1qwpV1dXrV27Vt99951KlSqlSZMmyc/PT0ePHnXyWSC9yODsAYAnyYcffqjy5cvLz8/Pvubv769NmzY5bLdp0yaVKFFCrq6uj3tEAEiWihUraunSpSpcuLA9YP/JYrGoWrVqqlatmoYMGSJfX18tX75cvXr1eszTIj3iyiqQDAEBAXrllVc0ceJE+1rv3r21bt06jRgxQn/88YfCw8M1efJk9enTx4mTAkDSdO/eXRcuXNDLL7+sbdu2KSoqSqtXr1bHjh2VkJCgrVu3atSoUfr111914sQJLVu2TOfOnZO/v7+zR0c6QawCyRQSEiKr1Wr/fcWKFbV48WItXLhQZcqU0ZAhQxQSEqLg4GDnDQkASZQ/f35t2rRJCQkJatiwoQICAvTuu+/Ky8tLLi4u8vT0VGRkpJo2baoSJUpo0KBBCgsLU5MmTZw9OtIJngYAAAAAY3FlFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUADBMcHKyWLVvaf1+7dm29++67j32ODRs2yGKx6NKlS4/92ABwF7EKAEkUHBwsi8Uii8WiTJkyqXjx4goJCdHt27dT9bjLli3TiBEjkrQtgQkgrcng7AEA4EnSuHFjzZo1S/Hx8fr222/VvXt3ZcyYUQMGDHDY7ubNm8qUKVOKHDNHjhwpsh8AeBJxZRUAksHNzU158+aVr6+v3nzzTdWvX19ff/21/Vv3I0eOVP78+eXn5ydJ+vPPP9WmTRt5eXkpR44catGihY4dO2bfX0JCgnr16iUvLy/5+PioX79+stlsDsf8520A8fHx6t+/vwoWLCg3NzcVL15cM2fO1LFjx1SnTh1Jkre3tywWi4KDgyVJVqtVoaGhKlKkiNzd3VWuXDktWbLE4TjffvutSpQoIXd3d9WpU8dhTgBwFmIVAB6Bu7u7bt68KUlat26dDh48qLVr1+qbb77RrVu31KhRI2XLlk0//fSTNm3aJA8PDzVu3Nj+nrCwMM2ePVuff/65Nm7cqAsXLmj58uX/eswOHTpowYIFmjhxog4cOKDp06fLw8NDBQsW1NKlSyVJBw8eVHR0tCZMmCBJCg0N1Zw5czRt2jTt27dPPXv21Kuvvqoff/xR0p2oDgwMVPPmzbVz50516dJF7733Xmp92QAgybgNAAAegs1m07p167R69Wr997//1blz55Q1a1bNmDHD/u3/L774QlarVTNmzJDFYpEkzZo1S15eXtqwYYMaNmyo8ePHa8CAAQoMDJQkTZs2TatXr77vcf/44w8tXrxYa9euVf369SVJRYsWtb9+95aB3Llzy8vLS9KdK7GjRo3S999/rypVqtjfs3HjRk2fPl21atXS1KlTVaxYMYWFhUmS/Pz8tGfPHo0ePToFv2oAkHzEKgAkwzfffCMPDw/dunVLVqtV7du317Bhw9S9e3cFBAQ43Ke6a9cuHT58WNmyZXPYx40bNxQVFaXLly8rOjpalStXtr+WIUMGPfPMM4luBbhr586dcnV1Va1atZI88+HDhxUbG6sGDRo4rN+8eVMVKlSQJB04cMBhDkn2sAUAZyJWASAZ6tSpo6lTpypTpkzKnz+/MmT431+jWbNmddj22rVrqlSpkubNm5doP7ly5Xqo47u7uyf7PdeuXZMkrVy5Uk899ZTDa25ubg81BwA8LsQqACRD1qxZVbx48SRtW7FiRS1atEi5c+eWp6fnPbfJly+ftm7dqpo1a0qSbt++rd9++00VK1a85/YBAQGyWq368ccf7bcB/N3dK7sJCQn2tVKlSsnNzU0nTpy47xVZf39/ff311w5rW7ZsefBJAkAq4wNWAJBKXnnlFeXMmVMtWrTQTz/9pKNHj2rDhg165513dPLkSUlSjx499OGHHyoiIkK///673nrrrX99RmrhwoUVFBSkTp06KSIiwr7PxYsXS5J8fX1lsVj0zTff6Ny5c7p27ZqyZcumPn36qGfPngoPD1dUVJS2b9+uSZMmKTw8XJLUrVs3HTp0SH379tXBgwc1f/58zZ49O7W/RADwQMQqAKSSLFmyKDIyUoUKFVJgYKD8/f3VuXNn3bhxw36ltXfv3nrttdcUFBSkKlWqKFu2bGrVqtW/7nfq1Klq3bq13nrrLZUsWVKvv/66rl+/Lkl66qmnNHz4cL333nvKkyeP3n77bUnSiBEjNHjwYIWGhsrf31+NGzfWypUrVaRIEUlSoUKFtHTpUkVERKhcuXKaNm2aRo0alYpfHQBIGovtfnfxAwAAAE7GlVUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABjr/wA29SLQtggGNwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets use the hyperparameters to train the model again\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = best_rf_classifier.predict(X_test)\n",
    "print(\"Accuracy of Random Forrest with hyperparameters: \", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, rf_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# After the grid search we can see that the accuracy has improved a bit, but its still not great.\n",
    "# We can tell from the confusion matrix that the model is not very good at predicting the positive class, which is when a heart attack occurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Exporting the models\n",
    "import pickle\n",
    "\n",
    "# Lets save the models and their accuracies\n",
    "\n",
    "\n",
    "rf = {\n",
    "    'RandomForest': rf_classifier,\n",
    "    'RandomForestAccuracy': accuracy_score(y_test, rf_predictions),\n",
    "    'RandomForestReport': classification_report(y_test, rf_predictions),\n",
    "}\n",
    "dc = {\n",
    "    'DecisionTree': dt_classifier,\n",
    "    'DecisionTreeAccuracy': accuracy_score(y_test, dt_predictions),\n",
    "    'DecisionTreeReport': classification_report(y_test, dt_predictions),\n",
    "}\n",
    "\n",
    "nb = {\n",
    "    'NaiveBayes': nb_classifier,\n",
    "    'NaiveBayesAccuracy': accuracy_score(y_test, nb_predictions),\n",
    "    'NaiveBayesReport': classification_report(y_test, nb_predictions),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "with open('../Data/models/rfModel.pkl', 'wb') as file:\n",
    "    pickle.dump(rf, file)\n",
    "\n",
    "with open('../Data/models/DTmodels.pkl', 'ab') as file:\n",
    "    pickle.dump(dc, file)\n",
    "    \n",
    "with open('../Data/models/nbModel.pkl', 'wb') as file:\n",
    "    pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can we tell from all of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of models\n",
    "\n",
    "We are working with a classification problem: If the person have a heart attack or not. We therefore have selected the three models from previous success in the Business Intelligence course:\n",
    "1. Decision Tree\n",
    "2. Random Forest \n",
    "3. Naive Bayes.\n",
    "\n",
    "From our experience its always a good thing to include a standard Decision tree.\n",
    "We also includes Random Forest, which is a \"Forest\" of decision trees trained on different parts of the training data, which in terms makes it more precise.\n",
    "Naive bayes have been performing well in earlier projects with relatively low performance hits.\n",
    "\n",
    "\n",
    "### Selection of the best fit model\n",
    "\n",
    "Based on the evaluation metrics—particularly accuracy, F1 score, and recall—we can see that Random Forest achieved the highest overall accuracy at ~87.8%, the same as Naive Bayes, and higher than Decision Tree (~76.5%).\n",
    "\n",
    "However, accuracy alone is not a reliable metric in our case due to class imbalance (i.e., far more non-heart attack cases than heart attack cases). This is evident because all models show significantly worse performance on class 1 (heart attack), with very low recall and F1 scores.\n",
    "\n",
    "Random Forest: Predicts the majority class (0) very well but completely misses class 1 (recall = 0.00), resulting in an F1 score of 0.00 for that class.\n",
    "\n",
    "Naive Bayes: Also achieves high accuracy, but like Random Forest, it struggles to identify class 1.\n",
    "\n",
    "Decision Tree: Slightly lower accuracy overall, but does slightly better at identifying class 1 (F1 = 0.13), showing a better balance between both classes, albeit still far from ideal.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "While Random Forest shows the best accuracy and is typically a strong model, its inability to identify the minority class (heart attack cases) is a critical issue in this context, especially given the potential consequences of missing a heart attack prediction.\n",
    "\n",
    "Therefore, despite the lower accuracy, the Decision Tree shows slightly better sensitivity to class 1. However, none of the models currently perform well enough to be considered \"good\" at detecting heart attacks, and further work (e.g., resampling, better feature engineering, or using specialized models for imbalanced data) is necessary.\n",
    "\n",
    "### Explanation of what overfitting means and how we can spot it\n",
    "\n",
    "\n",
    "Overfitting happens when a model learns the training data too well, including noise and outliers, making it perform poorly on unseen data. It essentially \"memorizes\" rather than \"generalizes\".\n",
    "\n",
    "We can spot overfitting when:\n",
    "The model performs very well on training data but poorly on test data.\n",
    "There is a large gap between training and test accuracy.\n",
    "The model consistently predicts the majority class in an imbalanced dataset (as we see with Random Forest predicting mostly class 0).\n",
    "\n",
    "In our case, models like Random Forest showed perfect recall for class 0 but zero recall for class 1, indicating possible overfitting to the majority class.\n",
    "\n",
    "### Explain what hyperparameters you have adjusted and why\n",
    "\n",
    "We performed hyperparameter tuning on the Random Forest classifier to optimize its performance. The following were adjusted:\n",
    "\n",
    "- n_estimators: Number of trees in the forest. More trees generally increase performance but also training time. (Tested: 100, 200, 300)\n",
    "- max_depth: Controls how deep each tree can grow. Limiting this helps prevent overfitting. (Tested: None, 10, 20, 30)\n",
    "- min_samples_split: Minimum number of samples needed to split an internal node. Helps reduce model complexity. (Tested: 2, 5, 10)\n",
    "- min_samples_leaf: Minimum number of samples needed at a leaf node. A higher value helps in smoothing the model. (Tested: 1, 2, 4)\n",
    "\n",
    "These parameters were chosen to balance between model complexity and generalization, using GridSearchCV to find the best combination.\n",
    "However we did not get a better result from changing these parameters, the accuracy for predicting non-heart attacks went up by ~1 %.\n",
    "\n",
    "\n",
    "### Explain how you have measured quality using F1 score and explain the terms accuracy, precision and recall (sensitivity).\n",
    "\n",
    "To evaluate our models, we used several key metrics:\n",
    "\n",
    "- **Accuracy**: The percentage of total predictions the model got right.  \n",
    "  Formula: `Accuracy = (True Positives + True Negatives) / Total Predictions`\n",
    "\n",
    "- **Precision**: Out of all positive predictions, how many were actually positive.  \n",
    "  Formula: `Precision = True Positives / (True Positives + False Positives)`\n",
    "\n",
    "- **Recall (Sensitivity)**: Out of all actual positives, how many did we correctly identify.  \n",
    "  Formula: `Recall = True Positives / (True Positives + False Negatives)`\n",
    "\n",
    "- **F1 Score**: Harmonic mean of precision and recall. It balances both and is especially useful when dealing with imbalanced classes.  \n",
    "  Formula: `F1 Score = 2 * (Precision * Recall) / (Precision + Recall)`\n",
    "\n",
    "Since our dataset is imbalanced (fewer heart attack cases), the **F1 score** is more informative than accuracy. A model can have high accuracy by predicting only the majority class, but that’s misleading. The F1 score shows how well the model identifies both classes, especially the minority class (heart attacks).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
